{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tymothy6/colab/blob/main/Real_time_(ish)_Whisper_transcription_%5BGradio%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ockUswiTYRky"
      },
      "source": [
        "### 1. Install dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q-U4U4LysJ3H"
      },
      "source": [
        "The OpenAI Python library is used to make API calls to Whisper and GPT. Gradio is used to create the user interface for audio input and transcription outputs. The PyDub library is used to chunk the recorded audio into segments to mimic real-time transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQCDfZSYzfoF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/73/0a/792d54defeefbe900140bb56f08b8375f4bbe240ed534a42bb6364989b5d/gradio-3.44.3-py3-none-any.whl.metadata\n",
            "  Downloading gradio-3.44.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Obtaining dependency information for aiofiles<24.0,>=22.0 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
            "  Obtaining dependency information for altair<6.0,>=4.2.0 from https://files.pythonhosted.org/packages/f2/b4/02a0221bd1da91f6e6acdf0525528db24b4b326a670a9048da474dfe0667/altair-5.1.1-py3-none-any.whl.metadata\n",
            "  Using cached altair-5.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting fastapi (from gradio)\n",
            "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/76/e5/ca411b260caa4e72f9ac5482f331fe74fd4eb5b97aa74d1d2806ccf07e2c/fastapi-0.103.1-py3-none-any.whl.metadata\n",
            "  Using cached fastapi-0.103.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.3.1-py3-none-any.whl\n",
            "Collecting gradio-client==0.5.0 (from gradio)\n",
            "  Obtaining dependency information for gradio-client==0.5.0 from https://files.pythonhosted.org/packages/fe/85/ec0323f39192c4bee04e8e06e64213aff816b9d1b61c3c8367e75b1c7e10/gradio_client-0.5.0-py3-none-any.whl.metadata\n",
            "  Using cached gradio_client-0.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx (from gradio)\n",
            "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/33/0d/d9ce469af019741c8999711d36b270ff992ceb1a0293f73f9f34fdf131e9/httpx-0.25.0-py3-none-any.whl.metadata\n",
            "  Using cached httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Obtaining dependency information for huggingface-hub>=0.14.0 from https://files.pythonhosted.org/packages/50/9d/5eac2733606df7d164b951b14cd76b056e530af96c881aaec89383bdbe45/huggingface_hub-0.17.1-py3-none-any.whl.metadata\n",
            "  Using cached huggingface_hub-0.17.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
            "  Obtaining dependency information for importlib-resources<7.0,>=1.3 from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
            "  Using cached importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jinja2<4.0 (from gradio)\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Obtaining dependency information for markupsafe~=2.0 from https://files.pythonhosted.org/packages/20/1d/713d443799d935f4d26a4f1510c9e61b1d288592fb869845e5cc92a1e055/MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
            "  Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib~=3.0 (from gradio)\n",
            "  Obtaining dependency information for matplotlib~=3.0 from https://files.pythonhosted.org/packages/c4/03/ee54da5a3f26d7b54861105291b583f9824b3c3608ae77b789cf7592b97a/matplotlib-3.7.3-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached matplotlib-3.7.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
            "Collecting numpy~=1.0 (from gradio)\n",
            "  Obtaining dependency information for numpy~=1.0 from https://files.pythonhosted.org/packages/c3/ea/1d95b399078ecaa7b5d791e1fdbb3aee272077d9fd5fb499593c87dec5ea/numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Obtaining dependency information for orjson~=3.0 from https://files.pythonhosted.org/packages/fa/e2/376b07aa93994449b10848a11b06ff534d888f159863c208231135f26a90/orjson-3.9.7-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
            "  Using cached orjson-3.9.7-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from gradio) (23.1)\n",
            "Collecting pandas<3.0,>=1.0 (from gradio)\n",
            "  Obtaining dependency information for pandas<3.0,>=1.0 from https://files.pythonhosted.org/packages/8d/08/1cf87814dcd87604807971abc743b12e635de36d820be7b50e2b6aa9e1b5/pandas-2.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached pandas-2.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio)\n",
            "  Obtaining dependency information for pillow<11.0,>=8.0 from https://files.pythonhosted.org/packages/ef/53/024e161112beb11008d6c7529c954e2ec641ae17b99e03fe9a539e114ae6/Pillow-10.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached Pillow-10.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 (from gradio)\n",
            "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/82/06/fafdc75e48b248eff364b4249af4bcc6952225e8f20e8205820afc66e88e/pydantic-2.3.0-py3-none-any.whl.metadata\n",
            "  Using cached pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
            "  Obtaining dependency information for pyyaml<7.0,>=5.0 from https://files.pythonhosted.org/packages/5b/07/10033a403b23405a8fc48975444463d3d10a5c2736b7eb2550b07b367429/PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting requests~=2.0 (from gradio)\n",
            "  Obtaining dependency information for requests~=2.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting typing-extensions~=4.0 (from gradio)\n",
            "  Obtaining dependency information for typing-extensions~=4.0 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Obtaining dependency information for uvicorn>=0.14.0 from https://files.pythonhosted.org/packages/79/96/b0882a1c3f7ef3dd86879e041212ae5b62b4bd352320889231cc735a8e8f/uvicorn-0.23.2-py3-none-any.whl.metadata\n",
            "  Using cached uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Using cached websockets-11.0.3-cp310-cp310-macosx_11_0_arm64.whl (121 kB)\n",
            "Collecting fsspec (from gradio-client==0.5.0->gradio)\n",
            "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/3a/9f/b40e8e5be886143379000af5fc0c675352d59e82fd869d24bf784161dc77/fsspec-2023.9.0-py3-none-any.whl.metadata\n",
            "  Using cached fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio)\n",
            "  Obtaining dependency information for jsonschema>=3.0 from https://files.pythonhosted.org/packages/2b/ff/af59fd34bc4d7ac3e6e0cd1f3c10317d329b6c1aee179e8b24ad9a79fbac/jsonschema-4.19.0-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema-4.19.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.14.0->gradio)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
            "  Using cached filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.14.0->gradio)\n",
            "  Obtaining dependency information for tqdm>=4.42.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
            "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/15/c4/aae3954fce0e22362cc55430d1a395bf0be5a22b40fce63edda9eb6ea339/contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
            "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/21/66/bddd878452ae1e2d5f5891daa6bcce594d6b19396d33b8798e722837b222/fonttools-4.42.1-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
            "  Using cached fonttools-4.42.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (150 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gradio)\n",
            "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/23/11/6fb190bae4b279d712a834e7b1da89f6dcff6791132f7399aa28a57c3565/kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
            "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
            "  Using cached annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pydantic-core==2.6.3 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
            "  Obtaining dependency information for pydantic-core==2.6.3 from https://files.pythonhosted.org/packages/9c/60/15daecade2df0d85bcbd277195ca017d5214b236f4e7476df2423b723b8a/pydantic_core-2.6.3-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached pydantic_core-2.6.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests~=2.0->gradio)\n",
            "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/ec/a7/96835706283d63fefbbbb4f119d52f195af00fc747e67cc54397c56312c8/charset_normalizer-3.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached charset_normalizer-3.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting idna<4,>=2.5 (from requests~=2.0->gradio)\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests~=2.0->gradio)\n",
            "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
            "  Using cached urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests~=2.0->gradio)\n",
            "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
            "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting click>=7.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Obtaining dependency information for click>=7.0 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting anyio<4.0.0,>=3.7.1 (from fastapi->gradio)\n",
            "  Obtaining dependency information for anyio<4.0.0,>=3.7.1 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
            "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
            "  Using cached starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
            "  Obtaining dependency information for httpcore<0.19.0,>=0.18.0 from https://files.pythonhosted.org/packages/ac/97/724afbb7925339f6214bf1fdb5714d1a462690466832bf8fb3fd497649f1/httpcore-0.18.0-py3-none-any.whl.metadata\n",
            "  Using cached httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting sniffio (from httpx->gradio)\n",
            "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/1c/24/83349ac2189cc2435e84da3f69ba3c97314d3c0622628e55171c6798ed80/jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/be/8e/56d6f1e2d591f4d6cbcba446cac4a1b0dc4f584537e2071d9bcee8eeab6b/referencing-0.30.2-py3-none-any.whl.metadata\n",
            "  Using cached referencing-0.30.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/29/89/0a94b3210a5adc1d376e81c4712ad9d634a90d8765e569998fb9d2e4c29f/rpds_py-0.10.3-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached rpds_py-0.10.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Downloading gradio-3.44.3-py3-none-any.whl (20.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached altair-5.1.1-py3-none-any.whl (520 kB)\n",
            "Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "Using cached importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
            "Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
            "Using cached matplotlib-3.7.3-cp310-cp310-macosx_11_0_arm64.whl (7.3 MB)\n",
            "Using cached numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
            "Using cached orjson-3.9.7-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (242 kB)\n",
            "Using cached pandas-2.1.0-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
            "Using cached Pillow-10.0.0-cp310-cp310-macosx_11_0_arm64.whl (3.1 MB)\n",
            "Using cached pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
            "Using cached pydantic_core-2.6.3-cp310-cp310-macosx_11_0_arm64.whl (1.6 MB)\n",
            "Using cached PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Using cached uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "Using cached fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
            "Using cached httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
            "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "Using cached charset_normalizer-3.2.0-cp310-cp310-macosx_11_0_arm64.whl (124 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Using cached contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl (229 kB)\n",
            "Using cached fonttools-4.42.1-cp310-cp310-macosx_10_9_universal2.whl (2.7 MB)\n",
            "Using cached httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "Using cached jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
            "Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
            "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Using cached urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Using cached fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
            "Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n",
            "Using cached rpds_py-0.10.3-cp310-cp310-macosx_11_0_arm64.whl (322 kB)\n",
            "Installing collected packages: pytz, pydub, ffmpy, websockets, urllib3, tzdata, typing-extensions, tqdm, toolz, sniffio, semantic-version, rpds-py, pyyaml, python-multipart, pyparsing, pillow, orjson, numpy, markupsafe, kiwisolver, importlib-resources, idna, h11, fsspec, fonttools, filelock, cycler, click, charset-normalizer, certifi, attrs, annotated-types, aiofiles, uvicorn, requests, referencing, pydantic-core, pandas, jinja2, contourpy, anyio, starlette, pydantic, matplotlib, jsonschema-specifications, huggingface-hub, httpcore, jsonschema, httpx, fastapi, gradio-client, altair, gradio\n",
            "Successfully installed aiofiles-23.2.1 altair-5.1.1 annotated-types-0.5.0 anyio-3.7.1 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.7 contourpy-1.1.0 cycler-0.11.0 fastapi-0.103.1 ffmpy-0.3.1 filelock-3.12.4 fonttools-4.42.1 fsspec-2023.9.0 gradio-3.44.3 gradio-client-0.5.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.1 idna-3.4 importlib-resources-6.0.1 jinja2-3.1.2 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 kiwisolver-1.4.5 markupsafe-2.1.3 matplotlib-3.7.3 numpy-1.25.2 orjson-3.9.7 pandas-2.1.0 pillow-10.0.0 pydantic-2.3.0 pydantic-core-2.6.3 pydub-0.25.1 pyparsing-3.1.1 python-multipart-0.0.6 pytz-2023.3.post1 pyyaml-6.0.1 referencing-0.30.2 requests-2.31.0 rpds-py-0.10.3 semantic-version-2.10.0 sniffio-1.3.0 starlette-0.27.0 toolz-0.12.0 tqdm-4.66.1 typing-extensions-4.7.1 tzdata-2023.3 urllib3-2.0.4 uvicorn-0.23.2 websockets-11.0.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting openai\n",
            "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.10/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from openai) (4.66.1)\n",
            "Collecting aiohttp (from openai)\n",
            "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/fa/9e/49002fde2a97d7df0e162e919c31cf13aa9f184537739743d1239edd0e67/aiohttp-3.8.5-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached aiohttp-3.8.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Using cached multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Using cached yarl-1.9.2-cp310-cp310-macosx_11_0_arm64.whl (62 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/67/6a/55a49da0fa373ac9aa49ccd5b6393ecc183e2a0904d9449ea3ee1163e0b1/frozenlist-1.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Using cached frozenlist-1.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Using cached aiohttp-3.8.5-cp310-cp310-macosx_11_0_arm64.whl (343 kB)\n",
            "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Using cached frozenlist-1.4.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.0 multidict-6.0.4 openai-0.28.0 yarl-1.9.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pydub in ./.venv/lib/python3.10/site-packages (0.25.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gradio\n",
        "%pip install openai\n",
        "%pip install pydub"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sqerAIQ-YY6h"
      },
      "source": [
        "### 2. Define Whisper and GPT API calls and run the Gradio app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrg9FS7O0lMe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
        "import openai\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vDsl2Az5YYLi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tng/Dropbox/Github/colab/.venv/lib/python3.10/site-packages/gradio/processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Whisper API call\n",
        "def transcribe(audio):\n",
        "  with open(audio, \"rb\") as audio_file:\n",
        "    try:\n",
        "      response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "      transcription = response['text']\n",
        "      if not transcription:\n",
        "        return \"Error transcribing audio.\", \"\"\n",
        "\n",
        "      return transcription, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error: {e}\")\n",
        "      print(f\"API Response: {response.json() if response else 'No response'}\")\n",
        "      return f\"An error occurred: {e}\", \"\"\n",
        "\n",
        "\n",
        "# Post-processing with GPT4\n",
        "def generate_correction(transcription):\n",
        "  system_prompt = (\"You are a helpful assistant. Your task is to correct spelling, grammar, and appropriate punctuation in the transcribed text.\")\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": system_prompt\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\": transcription\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']\n",
        "\n",
        "def post_process(transcription):\n",
        "  return generate_correction(transcription)\n",
        "\n",
        "def main_function(audio, option):\n",
        "    transcription, error = transcribe(audio)\n",
        "    if error:\n",
        "      return error, \"\"\n",
        "    if option == \"Speech-to-text\":\n",
        "        return transcription, \"\"\n",
        "    elif option == \"Speech-to-text with post-processing\":\n",
        "        processed_text = post_process(transcription)\n",
        "        return transcription, processed_text\n",
        "\n",
        "# Gradio app\n",
        "\n",
        "audio_input = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Speech input\")\n",
        "option_dropdown = gr.Dropdown(choices=[\"Speech-to-text\", \"Speech-to-text with post-processing\"], label=\"Options\", value=\"Speech-to-text\")\n",
        "textbox_output = gr.Textbox(label=\"Text\")\n",
        "textbox_processed_output = gr.Textbox(label=\"Processed text\")\n",
        "\n",
        "\n",
        "whisper = gr.Interface(\n",
        "    fn=main_function,\n",
        "    inputs=[audio_input, option_dropdown],\n",
        "    outputs=[textbox_output, textbox_processed_output],\n",
        "    title=\"Whisper API\",\n",
        "    description=\"This is a demo of Whisper live transcription with GPT post-processing using the OpenAI API.\",\n",
        "    allow_flagging=\"never\", # disables the Flag feature\n",
        "    live=False  # when this is true the function is called in real-time, without needing to press the button\n",
        ")\n",
        "\n",
        "whisper.launch(debug=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Real-time transcription using Gradio state variables\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the `live` parameter of `gr.Interface` combined with state to mimic real-time transcription with the Whisper API. The idea is to periodically process audio chunks and accumulate the transcribed text without disrupting the user experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
        "import openai\n",
        "import gradio as gr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def transcribe_from_point(audio, last_point):\n",
        "    # Error handling when audio is empty\n",
        "    if not audio:\n",
        "        print(\"No audio file provided.\")\n",
        "        return \"\", last_point\n",
        "    # Load the audio file from the last point\n",
        "    audio_segment = AudioSegment.from_wav(audio)[last_point:]\n",
        "    \n",
        "    # If the new chunk is empty or too small, return without transcribing\n",
        "    if len(audio_segment) < 1000:  # less than 1 second\n",
        "        return \"\", last_point\n",
        "\n",
        "    # Save the new chunk to a temporary file for transcription\n",
        "    chunk_filename = \"temp_chunk.wav\"\n",
        "    audio_segment.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "    # Transcribe this chunk\n",
        "    with open(chunk_filename, \"rb\") as audio_file:\n",
        "        try:\n",
        "            response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "            os.remove(chunk_filename)  # delete the temporary file\n",
        "            if response['text']:\n",
        "                return response['text'], last_point + len(audio_segment)\n",
        "            else:\n",
        "                return \"\", last_point\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            os.remove(chunk_filename)  # delete the temporary file\n",
        "            return f\"An error occurred: {e}\", last_point\n",
        "        \n",
        "# Post-processing with GPT4\n",
        "def generate_correction(transcription):\n",
        "  system_prompt = (\"You are a helpful assistant. Your task is to correct spelling, grammar, and appropriate punctuation in the transcribed text.\")\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": system_prompt\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\": transcription\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']\n",
        "\n",
        "def post_process(transcription):\n",
        "  return generate_correction(transcription)\n",
        "\n",
        "def main_function(audio, option, last_point=0):\n",
        "    chunk_transcription, updated_point = transcribe_from_point(audio, last_point)\n",
        "    \n",
        "    if option == \"Speech-to-text\":\n",
        "        return chunk_transcription, \"\", updated_point\n",
        "    elif option == \"Speech-to-text with post-processing\":\n",
        "        total_transcription = post_process(chunk_transcription)\n",
        "        return chunk_transcription, total_transcription, updated_point\n",
        "\n",
        "# Gradio component definition\n",
        "audio_input = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Speech input\")\n",
        "option_dropdown = gr.Dropdown(choices=[\"Speech-to-text\", \"Speech-to-text with post-processing\"], label=\"Options\", value=\"Speech-to-text\")\n",
        "textbox_output = gr.Textbox(label=\"Transcript\")\n",
        "textbox_processed_output = gr.Textbox(label=\"Processed transcript\")\n",
        "last_processed_point = gr.State(value=0)\n",
        "\n",
        "whisper = gr.Interface(\n",
        "    fn=main_function,\n",
        "    inputs=[audio_input, option_dropdown, last_processed_point],\n",
        "    outputs=[textbox_output, textbox_processed_output, last_processed_point],\n",
        "    title=\"Whisper API\",\n",
        "    description=\"This is a demo of Whisper live transcription with GPT post-processing using the OpenAI API.\",\n",
        "    allow_flagging=\"never\",\n",
        "    live=True  # the transcribe function is called repeatedly without manual input\n",
        ")\n",
        "\n",
        "whisper.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNasD+F8qfkTSVQZfNAIepg",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
